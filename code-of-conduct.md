# Code of Conduct

## How do we plan to collaborate?
We will use GitLab for version control and issue-tracking.

We plan to meet in-person at least two days per week:
1. The first meeting will be for in-person work.
2. The second meeting will be for in-person code review and learning.

We will also work remotely using Discord to collaborate.

## How do we ensure that everyone in our group stays informed about the individual contributions?
Team members will be responsible for presenting their contributions during weekly meetings.

## How do we ensure knowledge transfer among our team members?
We will use pair programming and assign code reviews to the other team members. This will ensure that our whole team is familiar with all parts of the code.

## What is our usual communication plan?
Our usual communication is through Discord. Team members must inform others if they cannot attend planned meetings.

## How will we solve conflicts?
We will discuss the conflict as a group, try to resolve it, and if we do not come to an agreement, we will approach the TA. When the team is divided, we will go with a majority vote. We will always prioritize the minimum-viable product (MVP) before increasing scope.

## How do you plan to ensure responsible use of LLMs in your project and how do you transparently and traceably document the use of LLMs?  
We will try to make sure to fully understand what has been generated, otherwise we will not try to incorporate it. We will label LLM generated code with comments.
```
//OLLAMA: description of use
```

## After your discussion, initiate a "discussion" with a your locally running LLM (ie., not with Bing Chat, OpenAI ChatGPT, Google Bard, â€¦) where you at least feed section 3 of your code-of-conduct to seek for advice what may be missing or what could be improved. For this part, you are expected to experiment with your locally running LLM, for example by using the Gemma:7B model Links to an external site. from Google Links to an external site. in your ollama environment. For this part, create a screen cast so that you can transparently document your interaction with the LLM; your interactive chat must contain your CID when interacting with your locally running LLM. 

## Signed March 27, 2024
Nasit Vurgun
Daniel van den Heuvel
Kai Rowley
Sam Hardingham
